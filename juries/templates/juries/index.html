{% extends 'juries/base.html' %}
{% load staticfiles %}


{% block content %}
	<!-- <nav class="navbar navbar-expand-sm fixed-top justify-content-end">
			<a href="/consent" class="btn btn-lg btn-primary">Join the experiment</a>
	</nav> -->

<img src={% static "juries/img/title.jpg" %} border="0" alt="" class="display" />

<main class="flex-shrink-0" role="main">
	<section id="control" class="container-fluid">
		<div class="row">
			<div class="col-sm-1 col-xs-12"></div>
			<div class="col-sm-5 col-xs-12">
				<!-- <h1 class="headline">Help us build a fairer, safer internet</h1> -->
				<h1 class="headline">How can we build a fairer, safer internet?</h1>
			</div>
			<div class="col-sm-6 col-xs-12"></div>
		</div>

		<div class="row">

			<div class="col-md-1 col-sm-12"></div>
			<div class="col-md-5 col-sm-12">
				<p>From misinformation to hate speech, the struggle of <a href="https://motherboard.vice.com/en_us/article/xwk9zd/how-facebook-content-moderation-works" title="The Impossible Job: Inside Facebook’s Struggle to Moderate Two Billion People">moderating content on social media platforms</a> is a tremendously tricky balance of liberty and safety.</p>
				<p>The harms are real: <a href="http://www.pewinternet.org/2017/07/11/online-harassment-2017/" title="Online Harrassment 2017">More than a third of adults report</a> having been subjected to online harassment. <a href="https://ies.berkeley.edu/fake-news-and-crisis-europe" title="Fake news and the crisis of Europe">False rumors and misinformation</a> spread on platforms have led to <a href="https://www.poynter.org/fact-checking/2018/inside-whatsapps-battle-against-misinformation-in-india/" title="Inside WhatsApp’s battle against misinformation in India">mob violence</a> and put <a href="https://carnegieendowment.org/2018/05/23/russian-election-interference-europe-s-counter-to-fake-news-and-cyber-attacks-pub-76435" title="Russian Election Interference: Europe’s Counter to Fake News and Cyber Attacks">elections under scrutiny</a>. Conspiracy theories <a href="https://www.theverge.com/2018/10/27/18029490/cesar-sayoc-mail-bombs-twitter-instagram-misinformation" title="How platforms are driving users to misinformation about mail bombs">spread online</a>  endanger everyone, leading to <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwippZqZpIjhAhWlT98KHTbPBkQQFjAAegQIARAB&url=https%3A%2F%2Fwww.washingtonpost.com%2Fnews%2Fpost-nation%2Fwp%2F2016%2F08%2F22%2Fprosecutors-say-accused-charleston-church-gunman-self-radicalized-online%2F&usg=AOvVaw2jUsPsqkZ9ikWkyTjZvmiX" title="Prosecutors say Dylann Roof 'self-radicalized' online, wrote another manifesto">radicalization</a> and <a href="https://www.nytimes.com/2019/03/15/technology/facebook-youtube-christchurch-shooting.html" title="A Mass Murder of, and for, the Internet">mass violence</a>.</p>
				<p>Companies like Facebook, Twitter, and Google are <a href="https://www.nytimes.com/2018/12/27/world/facebook-moderators.html" title="Inside Facebook’s Secret Rulebook for Global Political Speech">entirely responsible for deciding</a> what can or cannot stay up. <a href="https://www.facebook.com/notes/mark-zuckerberg/a-blueprint-for-content-governance-and-enforcement/10156443129621634/" title="A Blueprint for Content Governance and Enforcement">AI-based algorithms</a> speed up the process, but how are the rules decided? Human moderators can be hired, but <a href="https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona" title="The Trauma Floor: The secret lives of Facebook moderators in America">at what cost to their mental health</a>?</p>
				<p>The internet has connected our world more connected than ever before, but we now risk losing it to the <a href="https://www.theatlantic.com/technology/archive/2015/06/the-tragedy-of-the-digital-commons/395129/" title="The Tragedy of the Digital Commons">tragedy of the “digital commons”</a>.</p>
			</div>

			<div class="col-md-1 col-sm-12"></div>

			<div class="col-md-4 col-sm-12">
				<div class="callout">

					<h3 class="yellow mt-0">Join a "Digital Jury"</h3>

					<p>We are researchers building a new system to make decisions around how content moderation rules are formed. Like doing jury duty, you will join a panel of “netizens” in deciding the hard questions on how content moderation rules should be formed using real cases.</p>
					<!-- <p>We’re at the frontier of building something new. We need your help.</p> -->

					{% if active %}
						<a href="/consent" class="btn btn-lg btn-primary">Start Experiment</a>
					{% else %}
						<p class="text-warning">Sorry, we are not taking participants right now.</p>
					{% endif %}
				</div>
			</div>
		</div>


		<div class="row">
			<div class="col-md-1 col-sm-12"></div>
			<div class="col-md-10 col-sm-12">

				<hr />
				
				<h3>Abstract</h3>

				<span class="yellow">Thank you for participating in this experiment! Our results and final paper have been selected to be published in <a href="https://chi2020.acm.org/" target="_blank">ACM CHI (Conference on Human Factors in Computing Systems)</a>, coming April 2020.</span>

				<p><em>As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.</em></p>

				<p><a href={% static "juries/Digital_Juries__CHI2020.pdf" %}>Download the full paper (PDF)</a></p>

				<iframe src={% static "juries/Digital_Juries__CHI2020.pdf" %} width="100%" height="500px" frameborder="0">
				</iframe>
			</div>
		</div>
	</section>

</main>

{% endblock %}
