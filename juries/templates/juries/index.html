{% extends 'juries/base.html' %}
{% load staticfiles %}


{% block content %}
	<!-- <nav class="navbar navbar-expand-sm fixed-top justify-content-end">
			<a href="/consent" class="btn btn-lg btn-primary">Join the experiment</a>
	</nav> -->

<img src={% static "juries/img/title.jpg" %} border="0" alt="" class="display" />

<main class="flex-shrink-0" role="main">
	<section id="control" class="container-fluid">
		<div class="row">
			<div class="col-sm-1 col-xs-12"></div>
			<div class="col-sm-5 col-xs-12">
				<h1 class="headline">Help us build a fairer, safer internet</h1>
			</div>
			<div class="col-sm-6 col-xs-12"></div>
		</div>

		<div class="row">

			<div class="col-md-1 col-sm-12"></div>
			<div class="col-md-5 col-sm-12">
				<p>From misinformation to hate speech, the struggle of <a href="https://motherboard.vice.com/en_us/article/xwk9zd/how-facebook-content-moderation-works" title="The Impossible Job: Inside Facebook’s Struggle to Moderate Two Billion People">moderating content on social media platforms</a> is a tremendously tricky balance of liberty and safety.</p>
				<p>The harms are real: <a href="http://www.pewinternet.org/2017/07/11/online-harassment-2017/" title="Online Harrassment 2017">More than a third of adults report</a> having been subjected to online harassment. <a href="https://ies.berkeley.edu/fake-news-and-crisis-europe" title="Fake news and the crisis of Europe">False rumors and misinformation</a> spread on platforms have led to <a href="https://www.poynter.org/fact-checking/2018/inside-whatsapps-battle-against-misinformation-in-india/" title="Inside WhatsApp’s battle against misinformation in India">mob violence</a> and put <a href="https://carnegieendowment.org/2018/05/23/russian-election-interference-europe-s-counter-to-fake-news-and-cyber-attacks-pub-76435" title="Russian Election Interference: Europe’s Counter to Fake News and Cyber Attacks">elections under scrutiny</a>. Conspiracy theories <a href="https://www.theverge.com/2018/10/27/18029490/cesar-sayoc-mail-bombs-twitter-instagram-misinformation" title="How platforms are driving users to misinformation about mail bombs">spread online</a>  endanger everyone, leading to <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwippZqZpIjhAhWlT98KHTbPBkQQFjAAegQIARAB&url=https%3A%2F%2Fwww.washingtonpost.com%2Fnews%2Fpost-nation%2Fwp%2F2016%2F08%2F22%2Fprosecutors-say-accused-charleston-church-gunman-self-radicalized-online%2F&usg=AOvVaw2jUsPsqkZ9ikWkyTjZvmiX" title="Prosecutors say Dylann Roof 'self-radicalized' online, wrote another manifesto">radicalization</a> and <a href="https://www.nytimes.com/2019/03/15/technology/facebook-youtube-christchurch-shooting.html" title="A Mass Murder of, and for, the Internet">mass violence</a>.</p>
				<p>Companies like Facebook, Twitter, and Google are <a href="https://www.nytimes.com/2018/12/27/world/facebook-moderators.html" title="Inside Facebook’s Secret Rulebook for Global Political Speech">entirely responsible for deciding</a> what can or cannot stay up. <a href="https://www.facebook.com/notes/mark-zuckerberg/a-blueprint-for-content-governance-and-enforcement/10156443129621634/" title="A Blueprint for Content Governance and Enforcement">AI-based algorithms</a> speed up the process, but how are the rules decided? Human moderators can be hired, but <a href="https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona" title="The Trauma Floor: The secret lives of Facebook moderators in America">at what cost to their mental health</a>?</p>
				<p>The internet has connected our world more connected than ever before, but we now risk losing it to the <a href="https://www.theatlantic.com/technology/archive/2015/06/the-tragedy-of-the-digital-commons/395129/" title="The Tragedy of the Digital Commons">tragedy of the “digital commons”</a>.</p>
			</div>

			<div class="col-md-1 col-sm-12"></div>

			<div class="col-md-4 col-sm-12">
				<div class="callout">
					<h3 class="yellow mt-0">Call for Volunteers</h3>

					<p>We are researchers looking for volunteers to test out a new system to make decisions around how content moderation rules are formed. Like doing jury duty, you will join a panel of “netizens” in deciding the hard questions on how content moderation rules should be formed using real cases.</p>
					<p>We’re at the frontier of building something new. We need your help.</p>

					<a href="/consent" class="btn btn-lg btn-primary">Join the Experiment</a>
				</div>
			</div>

		</div>
	</section>

</main>

{% endblock %}
